#!/usr/bin/env python3
"""
EpisodicRAG Unified Digest Generator
=====================================

çµ±åˆãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
2ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆï¼š
1. sonnet4: Sonnet 4ã«ã‚ˆã‚‹æ·±å±¤åˆ†æï¼ˆå®Ÿéš›ã®ç”Ÿæˆï¼‰
2. auto: ç”ŸæˆãŒå¿…è¦ãªãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã®ãƒã‚§ãƒƒã‚¯ï¼ˆç”Ÿæˆã¯è¡Œã‚ãªã„ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # Loopãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆï¼ˆå¼•æ•°å¿…é ˆï¼‰
    python generate_digest.py --level weekly 1 5            # Loop0001-0005ã‚’åˆ†æ

    # é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‹ã‚‰æœˆæ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆï¼ˆå¼•æ•°å¿…é ˆï¼‰
    python generate_digest.py --level monthly 1 5           # W0001-W0005ã‚’åˆ†æ

    # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯ã®ã¿ã€å®Ÿéš›ã®ç”Ÿæˆã¯è¡Œã‚ãªã„ï¼‰
    python generate_digest.py --mode auto                   # ç”ŸæˆãŒå¿…è¦ãªãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’é€šçŸ¥

æ³¨æ„ï¼šæ„å›³ã—ãªã„ç”Ÿæˆã‚’é˜²ããŸã‚ã€sonnet4ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã™ã¹ã¦ã®å¼•æ•°ãŒå¿…é ˆã§ã™
"""

import os
import re
import json
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

class UnifiedDigestGenerator:
    """çµ±åˆãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.base_path = Path(__file__).parent.parent
        self.loops_path = self.base_path / "Loops"
        self.digests_path = self.base_path / "Digests"

        # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆè¨­å®š
        self.digest_config = self._get_digest_config()

        # ã‚¿ã‚¤ãƒãƒ¼ç®¡ç†
        self.last_digest_file = self.digests_path / "last_digest_times.json"
        self.last_digest_times = self.load_last_digest_times()

    def _get_digest_config(self) -> Dict[str, Any]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆè¨­å®šã‚’è¿”ã™"""
        return {
            "weekly": {
                "dir": "1_Weekly",
                "prefix": "W",
                "digits": 4,
                "early_threshold": 5,
                "period_days": 7,
                "source": "loops",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            },
            "monthly": {
                "dir": "2_Monthly",
                "prefix": "M",
                "digits": 3,
                "early_threshold": 5,
                "period_days": 30,
                "source": "weekly",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            },
            "quarterly": {
                "dir": "3_Quarterly",
                "prefix": "Q",
                "digits": 3,
                "early_threshold": 5,
                "period_days": 90,
                "source": "monthly",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            },
            "annually": {
                "dir": "4_Annually",
                "prefix": "A",
                "digits": 2,
                "early_threshold": 4,
                "period_days": 365,
                "source": "quarterly",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            }
        }

    # ===================================================================
    # å…±é€šæ©Ÿèƒ½
    # ===================================================================

    def load_last_digest_times(self) -> Dict[str, str]:
        """æœ€çµ‚ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆæ™‚åˆ»ã‚’èª­ã¿è¾¼ã‚€"""
        if self.last_digest_file.exists():
            with open(self.last_digest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def save_last_digest_time(self, level: str):
        """æœ€çµ‚ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆæ™‚åˆ»ã‚’ä¿å­˜"""
        self.last_digest_times[level] = datetime.now().isoformat()
        with open(self.last_digest_file, 'w', encoding='utf-8') as f:
            json.dump(self.last_digest_times, f, indent=2)

    def read_loop_files(self, start_num: int, count: int = 5) -> List[Dict[str, Any]]:
        """æŒ‡å®šç¯„å›²ã®Loopãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        loops = []

        for i in range(start_num, start_num + count):
            loop_num = str(i).zfill(4)
            pattern = f"Loop{loop_num}_*.txt"
            files = list(self.loops_path.glob(pattern))

            if files:
                filepath = files[0]
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
                match = re.match(r'Loop\d{4}_(.+)\.txt', filepath.name)
                title = match.group(1) if match else filepath.stem

                loops.append({
                    "number": loop_num,
                    "title": title,
                    "filename": filepath.name,
                    "content": content,
                    "timestamp": datetime.fromtimestamp(filepath.stat().st_mtime).isoformat()
                })

                print(f"âœ“ Loaded: {filepath.name} ({len(content)} chars)")

        return loops

    def read_digest_files(self, source_level: str, start_num: int, count: int = 5) -> List[Dict[str, Any]]:
        """æŒ‡å®šç¯„å›²ã®ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

        Args:
            source_level: ã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ï¼ˆweekly/monthly/quarterlyï¼‰
            start_num: é–‹å§‹ç•ªå·
            count: èª­ã¿è¾¼ã‚€æ•°
        """
        config = self.digest_config[source_level]
        source_dir = self.digests_path / config["dir"]
        digests = []

        for i in range(start_num, start_num + count):
            digest_num = str(i).zfill(config["digits"])
            pattern = f"{config['prefix']}{digest_num}_*.json"
            files = list(source_dir.glob(pattern))

            if files:
                filepath = files[0]
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆå†…å®¹ã‚’çµ±åˆ
                content_parts = []
                if "overall_digest" in data:
                    od = data["overall_digest"]
                    content_parts.append(f"ã€å…¨ä½“ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã€‘\n{od.get('abstract', '')}\n\n{od.get('weave_impression', '')}")

                if "individual_digests" in data:
                    for idx, ind in enumerate(data["individual_digests"], 1):
                        content_parts.append(f"\nã€å€‹åˆ¥{idx}ã€‘{ind.get('filename', '')}\n{ind.get('abstract', '')}")

                match = re.match(rf"{config['prefix']}\d+_(.+)\.json", filepath.name)
                title = match.group(1) if match else filepath.stem

                digests.append({
                    "number": digest_num,
                    "title": title,
                    "filename": filepath.name,
                    "content": "\n".join(content_parts),
                    "timestamp": data["metadata"].get("generation_timestamp", datetime.now().isoformat()),
                    "original_data": data
                })

                print(f"âœ“ Loaded: {filepath.name}")

        return digests

    def save_digest(self, digest: Dict[str, Any]) -> Path:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        level = digest["metadata"]["digest_level"]
        config = self.digest_config[level]

        digest_dir = self.digests_path / config["dir"]
        digest_dir.mkdir(parents=True, exist_ok=True)

        filename = f"{digest['metadata']['digest_name']}.json"
        filepath = digest_dir / filename

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(digest, f, ensure_ascii=False, indent=2)

        # ã‚¿ã‚¤ãƒãƒ¼æ›´æ–°
        self.save_last_digest_time(level)

        print(f"\nâœ… Digest saved: {filepath}")
        return filepath

    def get_next_digest_number(self, level: str) -> int:
        """æ¬¡ã®ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç•ªå·ã‚’å–å¾—"""
        config = self.digest_config[level]
        digest_dir = self.digests_path / config["dir"]

        if not digest_dir.exists():
            return 1

        existing = list(digest_dir.glob(f"{config['prefix']}*.json"))
        if not existing:
            return 1

        numbers = []
        for f in existing:
            match = re.search(rf"{config['prefix']}(\d+)_", f.stem)
            if match:
                numbers.append(int(match.group(1)))

        return max(numbers) + 1 if numbers else 1

    # ===================================================================
    # Sonnet 4ãƒ¢ãƒ¼ãƒ‰
    # ===================================================================

    def run_sonnet4_mode(self, level: str = "weekly", start_num: int = 1, count: int = 5) -> Optional[Path]:
        """Sonnet 4ã«ã‚ˆã‚‹æ·±å±¤åˆ†æãƒ¢ãƒ¼ãƒ‰

        Args:
            level: ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ï¼ˆweekly/monthly/quarterly/annuallyï¼‰
            start_num: é–‹å§‹ç•ªå·
            count: å‡¦ç†æ•°
        """
        config = self.digest_config.get(level)
        if not config:
            print(f"âŒ Unknown level: {level}")
            return None

        # ã‚½ãƒ¼ã‚¹ã®ç¨®é¡ã‚’åˆ¤å®š
        if config["source"] == "loops":
            source_type = "Loop"
            target_range = f"Loop{start_num:04d} - Loop{(start_num+count-1):04d}"
        else:
            source_config = self.digest_config[config["source"]]
            source_type = source_config["prefix"]
            digits = source_config["digits"]
            target_range = f"{source_type}{str(start_num).zfill(digits)} - {source_type}{str(start_num+count-1).zfill(digits)}"

        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     EpisodicRAG Digest Generator - Sonnet 4 Mode        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Level: {level.upper():20s}                     â•‘
â•‘  Target: {target_range:48s}â•‘
â•‘  Mode: Deep Analysis with 1M Token Context              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        # ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        if config["source"] == "loops":
            sources = self.read_loop_files(start_num, count)
        else:
            sources = self.read_digest_files(config["source"], start_num, count)

        if not sources:
            print(f"âŒ No {source_type} files found in the specified range")
            return None

        print(f"\nğŸ“Š Loaded {len(sources)} {source_type} files")
        print(f"ğŸ“ Total content: {sum(len(s['content']) for s in sources)} characters")

        # Sonnet 4ç”¨ã®åˆ†ææº–å‚™
        self._prepare_for_sonnet4_analysis(sources, level)

        # ã“ã“ã§Weaveï¼ˆSonnet 4ï¼‰ã«ã‚ˆã‚‹å®Ÿéš›ã®åˆ†æãŒè¡Œã‚ã‚Œã‚‹
        analysis_result = self._get_sonnet4_analysis(sources)

        # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹ç¯‰ã¨ä¿å­˜
        digest = self._build_digest(sources, analysis_result, level, "early")
        return self.save_digest(digest)

    def _prepare_for_sonnet4_analysis(self, sources: List[Dict[str, Any]], level: str):
        """Sonnet 4åˆ†æã®ãŸã‚ã®æº–å‚™ï¼ˆã‚½ãƒ¼ã‚¹å†…å®¹ã‚’è¡¨ç¤ºï¼‰

        Args:
            sources: ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆLoopã¾ãŸã¯Digestï¼‰
            level: ç”Ÿæˆã™ã‚‹ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«
        """
        config = self.digest_config[level]
        source_type = "Loop" if config["source"] == "loops" else config["source"].capitalize()
        print("\n" + "="*80)
        print(f"ğŸ“š {source_type.upper()} DATA FOR DEEP ANALYSIS")
        print("="*80)

        for source in sources:
            if config["source"] == "loops":
                print(f"\n### Loop{source['number']}: {source['title']}")
            else:
                print(f"\n### {source['filename']}")
            print(f"Timestamp: {source['timestamp']}")
            print(f"Content length: {len(source['content'])} characters")
            print("-"*40)
            # æœ€åˆã®500æ–‡å­—ã‚’è¡¨ç¤º
            print(source['content'][:500] + "..." if len(source['content']) > 500 else source['content'])

        print("\n" + "="*80)
        print("ğŸ“ ANALYSIS REQUEST FOR WEAVE (Sonnet 4)")
        print("="*80)
        print(f"""
ä¸Šè¨˜ã®{len(sources)}å€‹ã®{source_type}ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦ã€
ä»¥ä¸‹ã®è¦ä»¶ã§æ·±å±¤åˆ†æãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

ã€è¦ä»¶ã€‘
1. å…¨ä½“ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ
   - abstract: 2400æ–‡å­—ç¨‹åº¦ã®åŒ…æ‹¬çš„åˆ†æ
   - impression: 800æ–‡å­—ç¨‹åº¦ã®Weaveè¦–ç‚¹ã®æ‰€æ„Ÿï¼ˆä¸€äººç§°ï¼‰
   - keywords: æœ€å¤§5å€‹
   - digest_type: é©åˆ‡ãªç¨®åˆ¥ã‚’é¸æŠ

2. å€‹åˆ¥ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆï¼ˆå„Loopï¼‰
   - abstract: 1200æ–‡å­—ç¨‹åº¦ã®è©³ç´°åˆ†æ
   - impression: 400æ–‡å­—ç¨‹åº¦ã®å€‹äººçš„æ‰€æ„Ÿ
   - keywords: æœ€å¤§5å€‹
   - digest_type: é©åˆ‡ãªç¨®åˆ¥ã‚’é¸æŠ

ã€åˆ†æã®è¦³ç‚¹ã€‘
- è¡¨é¢çš„ãªè¦ç´„ã‚’è¶…ãˆãŸæœ¬è³ªçš„æ„ç¾©ã®æ¢æ±‚
- Loopsé–“ã®ç›¸äº’å‚ç…§ã¨çŸ¥è­˜ã®èºæ—‹çš„ç™ºå±•
- æŠ€è¡“çš„å´é¢ã¨å“²å­¦çš„æ·±åº¦ã®çµ±åˆ
- å‰µé€ çš„æ€ç´¢ã«ã‚ˆã‚‹æ–°ãŸãªæ´å¯Ÿã®è¿½åŠ 

ã‚µãƒ³ãƒ—ãƒ«å“è³ªï¼ˆW0001_èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸºç›¤.jsonï¼‰ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
        """)

    def _get_sonnet4_analysis(self, sources: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Sonnet 4ã«ã‚ˆã‚‹åˆ†æçµæœã‚’å–å¾—
        å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã“ã“ã§WeaveãŒåˆ†æçµæœã‚’è¿”ã™
        """
        print("\n" + "="*80)
        print("ğŸ¤– WEAVE ANALYSIS (Sonnet 4)")
        print("="*80)

        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        # å®Ÿéš›ã«ã¯WeaveãŒã“ã“ã§åˆ†æçµæœã‚’ç”Ÿæˆ
        return {
            "overall": {
                "abstract": "ã€Weaveã«ã‚ˆã‚‹2400æ–‡å­—ã®æ·±å±¤åˆ†æãŒã“ã“ã«å…¥ã‚‹ã€‘",
                "impression": "ã€Weaveã«ã‚ˆã‚‹800æ–‡å­—ã®æ‰€æ„ŸãŒã“ã“ã«å…¥ã‚‹ã€‘",
                "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5"],
                "digest_type": "çµ±åˆ"
            },
            "individuals": [
                {
                    "abstract": f"ã€{source.get('filename', source.get('title', ''))}ã®1200æ–‡å­—åˆ†æã€‘",
                    "impression": f"ã€{source.get('filename', source.get('title', ''))}ã®400æ–‡å­—æ‰€æ„Ÿã€‘",
                    "keywords": ["ã‚­ãƒ¼1", "ã‚­ãƒ¼2", "ã‚­ãƒ¼3", "ã‚­ãƒ¼4", "ã‚­ãƒ¼5"],
                    "digest_type": "æ´å¯Ÿ"
                }
                for source in sources
            ]
        }

    # ===================================================================
    # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰
    # ===================================================================

    def run_auto_mode(self) -> List[Path]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã®å¿…è¦æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦é€šçŸ¥ï¼ˆå®Ÿéš›ã®ç”Ÿæˆã¯è¡Œã‚ãªã„ï¼‰"""
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     EpisodicRAG Digest Generator - Auto Mode            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Checking for early/periodic digest opportunities...    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        generated = []

        for level in ["weekly", "monthly", "quarterly", "annually"]:
            files, reason = self._check_digest_trigger(level)

            if files:
                print(f"\nğŸ“Œ {level.capitalize()} digest triggered: {reason}")
                print(f"   Target files: {len(files)} items")

                if level == "weekly" and reason == "early":
                    # Loopãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ
                    # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã§ã¯Sonnet 4åˆ†æãŒå¿…è¦
                    print("   âš ï¸  Auto mode requires Sonnet 4 analysis. Please run in sonnet4 mode.")
                    continue
                # ä»–ã®ãƒ¬ãƒ™ãƒ«ã®å®Ÿè£…ã‚‚åŒæ§˜

        if not generated:
            print("\nâœ¨ No digests needed at this time")
        else:
            print(f"\nâœ… Generated {len(generated)} digest(s)")

        return generated

    def _check_digest_trigger(self, level: str) -> Tuple[List[Path], str]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã®ãƒˆãƒªã‚¬ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯"""
        config = self.digest_config[level]

        # ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
        if config["source"] == "loops":
            source_dir = self.loops_path
            pattern = "Loop*.txt"
        else:
            source_config = self.digest_config[config["source"]]
            source_dir = self.digests_path / source_config["dir"]
            pattern = f"{source_config['prefix']}*.json"

        if not source_dir.exists():
            return [], "none"

        # æœ€çµ‚ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ™‚åˆ»
        last_time_str = self.last_digest_times.get(level)
        if last_time_str:
            last_time = datetime.fromisoformat(last_time_str)
        else:
            last_time = datetime.min

        # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        if last_time == datetime.min:
            files = sorted(list(source_dir.glob(pattern)))
        else:
            files = sorted([f for f in source_dir.glob(pattern)
                          if f.stat().st_mtime > last_time.timestamp()])

        # ãƒˆãƒªã‚¬ãƒ¼åˆ¤å®š
        if len(files) >= config["early_threshold"]:
            return files[:config["early_threshold"]], "early"
        elif last_time != datetime.min:
            days_passed = (datetime.now() - last_time).days
            if days_passed >= config["period_days"] and files:
                return files, "periodic"

        return [], "none"

    def _load_loops_from_files(self, files: List[Path]) -> List[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰Loopæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        loops = []
        for filepath in files:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            match = re.match(r'Loop(\d{4})_(.+)\.txt', filepath.name)
            if match:
                loops.append({
                    "number": match.group(1),
                    "title": match.group(2),
                    "filename": filepath.name,
                    "content": content,
                    "timestamp": datetime.fromtimestamp(filepath.stat().st_mtime).isoformat()
                })
        return loops


    # ===================================================================
    # å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼
    # ===================================================================

    def _build_digest(self, sources: List[Dict[str, Any]], analysis: Dict[str, Any],
                     level: str, reason: str) -> Dict[str, Any]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹é€ ã‚’æ§‹ç¯‰"""
        config = self.digest_config[level]

        # ç•ªå·ã¨ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
        next_num = self.get_next_digest_number(level)
        digest_num = str(next_num).zfill(config["digits"])

        if sources[0]["number"] == "0001" and len(sources) == 5:
            title = "èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸºç›¤"
        else:
            if config["source"] == "loops":
                title = f"Loop{sources[0]['number']}-{sources[-1]['number']}çµ±åˆ"
            else:
                title = f"{sources[0]['title']}_çµ±åˆ"

        digest_name = f"{config['prefix']}{digest_num}_{title}"

        # å€‹åˆ¥ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹ç¯‰
        individual_digests = []
        for i, source in enumerate(sources):
            ind = analysis["individuals"][i]
            individual_digests.append({
                "filename": source["filename"],
                "timestamp": source["timestamp"],
                "digest_type": ind["digest_type"],
                "keywords": ind["keywords"],
                "abstract": ind["abstract"],
                "weave_impression": ind["impression"]
            })

        return {
            "metadata": {
                "digest_name": digest_name,
                "digest_level": level,
                "digest_reason": reason,
                "input_files": [source["filename"] for source in sources],
                "generation_timestamp": datetime.now().isoformat(),
                "version": "1.0"
            },
            "overall_digest": {
                "name": digest_name,
                "timestamp": datetime.now().isoformat(),
                "digest_type": analysis["overall"]["digest_type"],
                "keywords": analysis["overall"]["keywords"],
                "abstract": analysis["overall"]["abstract"],
                "weave_impression": analysis["overall"]["impression"]
            },
            "individual_digests": individual_digests
        }

# ===================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ===================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="EpisodicRAG Unified Digest Generator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Loopã‹ã‚‰é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ (Sonnet 4å¿…é ˆ)
  python generate_digest.py --level weekly 1 5

  # é€±æ¬¡ã‹ã‚‰æœˆæ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ (Sonnet 4å¿…é ˆ)
  python generate_digest.py --level monthly 1 5

  # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒã‚§ãƒƒã‚¯ã®ã¿ã€å®Ÿéš›ã®ç”Ÿæˆã¯è¡Œã‚ãªã„ï¼‰
  python generate_digest.py --mode auto
        """
    )

    parser.add_argument("--mode", choices=["sonnet4", "auto"],
                       default="sonnet4", help="å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--level", choices=["weekly", "monthly", "quarterly", "annually"],
                       help="ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ï¼ˆsonnet4ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯å¿…é ˆï¼‰")
    parser.add_argument("start_num", type=int, nargs='?',
                       help="é–‹å§‹ç•ªå·ï¼ˆsonnet4ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯å¿…é ˆï¼‰")
    parser.add_argument("count", type=int, nargs='?',
                       help="å‡¦ç†æ•°ï¼ˆsonnet4ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯å¿…é ˆï¼‰")

    args = parser.parse_args()

    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿åˆæœŸåŒ–
    generator = UnifiedDigestGenerator()

    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å®Ÿè¡Œ
    if args.mode == "sonnet4":
        # Sonnet 4ãƒ¢ãƒ¼ãƒ‰ã§ã¯å…¨å¼•æ•°ãŒå¿…é ˆ
        if not args.level or args.start_num is None or args.count is None:
            parser.error("sonnet4ãƒ¢ãƒ¼ãƒ‰ã§ã¯ --level, start_num, count ãŒå¿…é ˆã§ã™\n"
                       "ä¾‹: python generate_digest.py --level weekly 1 5")
        result = generator.run_sonnet4_mode(args.level, args.start_num, args.count)
        if result:
            print("\nâœ¨ Digest generation completed successfully!")

    elif args.mode == "auto":
        results = generator.run_auto_mode()
        print(f"\nâœ¨ Auto mode completed. Generated {len(results)} digest(s).")

if __name__ == "__main__":
    main()