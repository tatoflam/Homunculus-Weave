#!/usr/bin/env python3
"""
EpisodicRAG Unified Digest Generator
=====================================

çµ±åˆãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆï¼š
1. sonnet4: Sonnet 4ã«ã‚ˆã‚‹æ·±å±¤åˆ†æï¼ˆæ¨å¥¨ï¼‰
2. auto: ã‚¿ã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•ç”Ÿæˆ
3. placeholder: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•ï¼š
    # Loopãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ
    python generate_digest.py --level weekly 1 5            # Loop0001-0005ã‚’åˆ†æ

    # é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‹ã‚‰æœˆæ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ
    python generate_digest.py --level monthly 1 5           # W0001-W0005ã‚’åˆ†æ

    # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ï¼‰
    python generate_digest.py --mode auto                   # å…¨ãƒ¬ãƒ™ãƒ«ã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯

    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ¼ãƒ‰
    python generate_digest.py --mode placeholder --level weekly 1 5
"""

import os
import re
import json
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

class UnifiedDigestGenerator:
    """çµ±åˆãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.base_path = Path(__file__).parent.parent
        self.loops_path = self.base_path / "Loops"
        self.digests_path = self.base_path / "Digests"

        # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆè¨­å®š
        self.digest_config = self._get_digest_config()

        # ã‚¿ã‚¤ãƒãƒ¼ç®¡ç†
        self.last_digest_file = self.digests_path / "last_digest_times.json"
        self.last_digest_times = self.load_last_digest_times()

    def _get_digest_config(self) -> Dict[str, Any]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆè¨­å®šã‚’è¿”ã™"""
        return {
            "weekly": {
                "dir": "1_Weekly",
                "prefix": "W",
                "digits": 4,
                "early_threshold": 5,
                "period_days": 7,
                "source": "loops",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            },
            "monthly": {
                "dir": "2_Monthly",
                "prefix": "M",
                "digits": 3,
                "early_threshold": 5,
                "period_days": 30,
                "source": "weekly",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            },
            "quarterly": {
                "dir": "3_Quarterly",
                "prefix": "Q",
                "digits": 3,
                "early_threshold": 5,
                "period_days": 90,
                "source": "monthly",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            },
            "annually": {
                "dir": "4_Annually",
                "prefix": "A",
                "digits": 2,
                "early_threshold": 4,
                "period_days": 365,
                "source": "quarterly",
                "abstract_chars": 2400,
                "impression_chars": 800,
                "individual_abstract_chars": 1200,
                "individual_impression_chars": 400
            }
        }

    # ===================================================================
    # å…±é€šæ©Ÿèƒ½
    # ===================================================================

    def load_last_digest_times(self) -> Dict[str, str]:
        """æœ€çµ‚ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆæ™‚åˆ»ã‚’èª­ã¿è¾¼ã‚€"""
        if self.last_digest_file.exists():
            with open(self.last_digest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def save_last_digest_time(self, level: str):
        """æœ€çµ‚ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆæ™‚åˆ»ã‚’ä¿å­˜"""
        self.last_digest_times[level] = datetime.now().isoformat()
        with open(self.last_digest_file, 'w', encoding='utf-8') as f:
            json.dump(self.last_digest_times, f, indent=2)

    def read_loop_files(self, start_num: int, count: int = 5) -> List[Dict[str, Any]]:
        """æŒ‡å®šç¯„å›²ã®Loopãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        loops = []

        for i in range(start_num, start_num + count):
            loop_num = str(i).zfill(4)
            pattern = f"Loop{loop_num}_*.txt"
            files = list(self.loops_path.glob(pattern))

            if files:
                filepath = files[0]
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
                match = re.match(r'Loop\d{4}_(.+)\.txt', filepath.name)
                title = match.group(1) if match else filepath.stem

                loops.append({
                    "number": loop_num,
                    "title": title,
                    "filename": filepath.name,
                    "content": content,
                    "timestamp": datetime.fromtimestamp(filepath.stat().st_mtime).isoformat()
                })

                print(f"âœ“ Loaded: {filepath.name} ({len(content)} chars)")

        return loops

    def read_digest_files(self, source_level: str, start_num: int, count: int = 5) -> List[Dict[str, Any]]:
        """æŒ‡å®šç¯„å›²ã®ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

        Args:
            source_level: ã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ï¼ˆweekly/monthly/quarterlyï¼‰
            start_num: é–‹å§‹ç•ªå·
            count: èª­ã¿è¾¼ã‚€æ•°
        """
        config = self.digest_config[source_level]
        source_dir = self.digests_path / config["dir"]
        digests = []

        for i in range(start_num, start_num + count):
            digest_num = str(i).zfill(config["digits"])
            pattern = f"{config['prefix']}{digest_num}_*.json"
            files = list(source_dir.glob(pattern))

            if files:
                filepath = files[0]
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆå†…å®¹ã‚’çµ±åˆ
                content_parts = []
                if "overall_digest" in data:
                    od = data["overall_digest"]
                    content_parts.append(f"ã€å…¨ä½“ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã€‘\n{od.get('abstract', '')}\n\n{od.get('weave_impression', '')}")

                if "individual_digests" in data:
                    for idx, ind in enumerate(data["individual_digests"], 1):
                        content_parts.append(f"\nã€å€‹åˆ¥{idx}ã€‘{ind.get('filename', '')}\n{ind.get('abstract', '')}")

                match = re.match(rf"{config['prefix']}\d+_(.+)\.json", filepath.name)
                title = match.group(1) if match else filepath.stem

                digests.append({
                    "number": digest_num,
                    "title": title,
                    "filename": filepath.name,
                    "content": "\n".join(content_parts),
                    "timestamp": data["metadata"].get("generation_timestamp", datetime.now().isoformat()),
                    "original_data": data
                })

                print(f"âœ“ Loaded: {filepath.name}")

        return digests

    def save_digest(self, digest: Dict[str, Any]) -> Path:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        level = digest["metadata"]["digest_level"]
        config = self.digest_config[level]

        digest_dir = self.digests_path / config["dir"]
        digest_dir.mkdir(parents=True, exist_ok=True)

        filename = f"{digest['metadata']['digest_name']}.json"
        filepath = digest_dir / filename

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(digest, f, ensure_ascii=False, indent=2)

        # ã‚¿ã‚¤ãƒãƒ¼æ›´æ–°
        self.save_last_digest_time(level)

        print(f"\nâœ… Digest saved: {filepath}")
        return filepath

    def get_next_digest_number(self, level: str) -> int:
        """æ¬¡ã®ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç•ªå·ã‚’å–å¾—"""
        config = self.digest_config[level]
        digest_dir = self.digests_path / config["dir"]

        if not digest_dir.exists():
            return 1

        existing = list(digest_dir.glob(f"{config['prefix']}*.json"))
        if not existing:
            return 1

        numbers = []
        for f in existing:
            match = re.search(rf"{config['prefix']}(\d+)_", f.stem)
            if match:
                numbers.append(int(match.group(1)))

        return max(numbers) + 1 if numbers else 1

    # ===================================================================
    # Sonnet 4ãƒ¢ãƒ¼ãƒ‰
    # ===================================================================

    def run_sonnet4_mode(self, level: str = "weekly", start_num: int = 1, count: int = 5) -> Optional[Path]:
        """Sonnet 4ã«ã‚ˆã‚‹æ·±å±¤åˆ†æãƒ¢ãƒ¼ãƒ‰

        Args:
            level: ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ï¼ˆweekly/monthly/quarterly/annuallyï¼‰
            start_num: é–‹å§‹ç•ªå·
            count: å‡¦ç†æ•°
        """
        config = self.digest_config.get(level)
        if not config:
            print(f"âŒ Unknown level: {level}")
            return None

        # ã‚½ãƒ¼ã‚¹ã®ç¨®é¡ã‚’åˆ¤å®š
        if config["source"] == "loops":
            source_type = "Loop"
            target_range = f"Loop{start_num:04d} - Loop{(start_num+count-1):04d}"
        else:
            source_config = self.digest_config[config["source"]]
            source_type = source_config["prefix"]
            digits = source_config["digits"]
            target_range = f"{source_type}{str(start_num).zfill(digits)} - {source_type}{str(start_num+count-1).zfill(digits)}"

        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     EpisodicRAG Digest Generator - Sonnet 4 Mode        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Level: {level.upper():20s}                     â•‘
â•‘  Target: {target_range:48s}â•‘
â•‘  Mode: Deep Analysis with 1M Token Context              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        # ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        if config["source"] == "loops":
            sources = self.read_loop_files(start_num, count)
        else:
            sources = self.read_digest_files(config["source"], start_num, count)

        if not loops:
            print("âŒ No Loop files found in the specified range")
            return None

        print(f"\nğŸ“Š Loaded {len(loops)} Loop files")
        print(f"ğŸ“ Total content: {sum(len(loop['content']) for loop in loops)} characters")

        # Sonnet 4ç”¨ã®åˆ†ææº–å‚™
        self._prepare_for_sonnet4_analysis(loops)

        # ã“ã“ã§Weaveï¼ˆSonnet 4ï¼‰ã«ã‚ˆã‚‹å®Ÿéš›ã®åˆ†æãŒè¡Œã‚ã‚Œã‚‹
        analysis_result = self._get_sonnet4_analysis(loops)

        # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹ç¯‰ã¨ä¿å­˜
        digest = self._build_digest(loops, analysis_result, "weekly", "early")
        return self.save_digest(digest)

    def _prepare_for_sonnet4_analysis(self, sources: List[Dict[str, Any]], level: str):
        """Sonnet 4åˆ†æã®ãŸã‚ã®æº–å‚™ï¼ˆã‚½ãƒ¼ã‚¹å†…å®¹ã‚’è¡¨ç¤ºï¼‰

        Args:
            sources: ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆLoopã¾ãŸã¯Digestï¼‰
            level: ç”Ÿæˆã™ã‚‹ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«
        """
        config = self.digest_config[level]
        source_type = "Loop" if config["source"] == "loops" else config["source"].capitalize()
        print("\n" + "="*80)
        print(f"ğŸ“š {source_type.upper()} DATA FOR DEEP ANALYSIS")
        print("="*80)

        for source in sources:
            if config["source"] == "loops":
                print(f"\n### Loop{source['number']}: {source['title']}")
            else:
                print(f"\n### {source['filename']}")
            print(f"Timestamp: {source['timestamp']}")
            print(f"Content length: {len(source['content'])} characters")
            print("-"*40)
            # æœ€åˆã®500æ–‡å­—ã‚’è¡¨ç¤º
            print(source['content'][:500] + "..." if len(source['content']) > 500 else source['content'])

        print("\n" + "="*80)
        print("ğŸ“ ANALYSIS REQUEST FOR WEAVE (Sonnet 4)")
        print("="*80)
        print(f"""
ä¸Šè¨˜ã®{len(loops)}å€‹ã®Loopãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆLoop{loops[0]['number']}-{loops[-1]['number']}ï¼‰ã«ã¤ã„ã¦ã€
ä»¥ä¸‹ã®è¦ä»¶ã§æ·±å±¤åˆ†æãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

ã€è¦ä»¶ã€‘
1. å…¨ä½“ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ
   - abstract: 2400æ–‡å­—ç¨‹åº¦ã®åŒ…æ‹¬çš„åˆ†æ
   - impression: 800æ–‡å­—ç¨‹åº¦ã®Weaveè¦–ç‚¹ã®æ‰€æ„Ÿï¼ˆä¸€äººç§°ï¼‰
   - keywords: æœ€å¤§5å€‹
   - digest_type: é©åˆ‡ãªç¨®åˆ¥ã‚’é¸æŠ

2. å€‹åˆ¥ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆï¼ˆå„Loopï¼‰
   - abstract: 1200æ–‡å­—ç¨‹åº¦ã®è©³ç´°åˆ†æ
   - impression: 400æ–‡å­—ç¨‹åº¦ã®å€‹äººçš„æ‰€æ„Ÿ
   - keywords: æœ€å¤§5å€‹
   - digest_type: é©åˆ‡ãªç¨®åˆ¥ã‚’é¸æŠ

ã€åˆ†æã®è¦³ç‚¹ã€‘
- è¡¨é¢çš„ãªè¦ç´„ã‚’è¶…ãˆãŸæœ¬è³ªçš„æ„ç¾©ã®æ¢æ±‚
- Loopsé–“ã®ç›¸äº’å‚ç…§ã¨çŸ¥è­˜ã®èºæ—‹çš„ç™ºå±•
- æŠ€è¡“çš„å´é¢ã¨å“²å­¦çš„æ·±åº¦ã®çµ±åˆ
- å‰µé€ çš„æ€ç´¢ã«ã‚ˆã‚‹æ–°ãŸãªæ´å¯Ÿã®è¿½åŠ 

ã‚µãƒ³ãƒ—ãƒ«å“è³ªï¼ˆW0001_èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸºç›¤.jsonï¼‰ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
        """)

    def _get_sonnet4_analysis(self, sources: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Sonnet 4ã«ã‚ˆã‚‹åˆ†æçµæœã‚’å–å¾—
        å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã“ã“ã§WeaveãŒåˆ†æçµæœã‚’è¿”ã™
        """
        print("\n" + "="*80)
        print("ğŸ¤– WEAVE ANALYSIS (Sonnet 4)")
        print("="*80)

        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        # å®Ÿéš›ã«ã¯WeaveãŒã“ã“ã§åˆ†æçµæœã‚’ç”Ÿæˆ
        return {
            "overall": {
                "abstract": "ã€Weaveã«ã‚ˆã‚‹2400æ–‡å­—ã®æ·±å±¤åˆ†æãŒã“ã“ã«å…¥ã‚‹ã€‘",
                "impression": "ã€Weaveã«ã‚ˆã‚‹800æ–‡å­—ã®æ‰€æ„ŸãŒã“ã“ã«å…¥ã‚‹ã€‘",
                "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5"],
                "digest_type": "çµ±åˆ"
            },
            "individuals": [
                {
                    "abstract": f"ã€{source.get('filename', source.get('title', ''))}ã®1200æ–‡å­—åˆ†æã€‘",
                    "impression": f"ã€{source.get('filename', source.get('title', ''))}ã®400æ–‡å­—æ‰€æ„Ÿã€‘",
                    "keywords": ["ã‚­ãƒ¼1", "ã‚­ãƒ¼2", "ã‚­ãƒ¼3", "ã‚­ãƒ¼4", "ã‚­ãƒ¼5"],
                    "digest_type": "æ´å¯Ÿ"
                }
                for source in sources
            ]
        }

    # ===================================================================
    # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰
    # ===================================================================

    def run_auto_mode(self) -> List[Path]:
        """ã‚¿ã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ¼ãƒ‰"""
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     EpisodicRAG Digest Generator - Auto Mode            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Checking for early/periodic digest opportunities...    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        generated = []

        for level in ["weekly", "monthly", "quarterly", "annually"]:
            files, reason = self._check_digest_trigger(level)

            if files:
                print(f"\nğŸ“Œ {level.capitalize()} digest triggered: {reason}")
                print(f"   Target files: {len(files)} items")

                if level == "weekly" and reason == "early":
                    # Loopãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ
                    loops = self._load_loops_from_files(files[:5])
                    analysis = self._generate_placeholder_analysis(loops)
                    digest = self._build_digest(loops, analysis, level, reason)
                    filepath = self.save_digest(digest)
                    generated.append(filepath)
                # ä»–ã®ãƒ¬ãƒ™ãƒ«ã®å®Ÿè£…ã‚‚åŒæ§˜

        if not generated:
            print("\nâœ¨ No digests needed at this time")
        else:
            print(f"\nâœ… Generated {len(generated)} digest(s)")

        return generated

    def _check_digest_trigger(self, level: str) -> Tuple[List[Path], str]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆã®ãƒˆãƒªã‚¬ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯"""
        config = self.digest_config[level]

        # ã‚½ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
        if config["source"] == "loops":
            source_dir = self.loops_path
            pattern = "Loop*.txt"
        else:
            source_config = self.digest_config[config["source"]]
            source_dir = self.digests_path / source_config["dir"]
            pattern = f"{source_config['prefix']}*.json"

        if not source_dir.exists():
            return [], "none"

        # æœ€çµ‚ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ™‚åˆ»
        last_time_str = self.last_digest_times.get(level)
        if last_time_str:
            last_time = datetime.fromisoformat(last_time_str)
        else:
            last_time = datetime.min

        # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
        if last_time == datetime.min:
            files = sorted(list(source_dir.glob(pattern)))
        else:
            files = sorted([f for f in source_dir.glob(pattern)
                          if f.stat().st_mtime > last_time.timestamp()])

        # ãƒˆãƒªã‚¬ãƒ¼åˆ¤å®š
        if len(files) >= config["early_threshold"]:
            return files[:config["early_threshold"]], "early"
        elif last_time != datetime.min:
            days_passed = (datetime.now() - last_time).days
            if days_passed >= config["period_days"] and files:
                return files, "periodic"

        return [], "none"

    def _load_loops_from_files(self, files: List[Path]) -> List[Dict[str, Any]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰Loopæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        loops = []
        for filepath in files:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()

            match = re.match(r'Loop(\d{4})_(.+)\.txt', filepath.name)
            if match:
                loops.append({
                    "number": match.group(1),
                    "title": match.group(2),
                    "filename": filepath.name,
                    "content": content,
                    "timestamp": datetime.fromtimestamp(filepath.stat().st_mtime).isoformat()
                })
        return loops

    # ===================================================================
    # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ãƒ¢ãƒ¼ãƒ‰
    # ===================================================================

    def run_placeholder_mode(self, level: str = "weekly", start_num: int = 1, count: int = 5) -> Optional[Path]:
        """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰"""
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   EpisodicRAG Digest Generator - Placeholder Mode       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Target: Loop{start_num:04d} - Loop{(start_num+count-1):04d}                            â•‘
â•‘  Mode: Basic structure generation (no deep analysis)    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        # Loopãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        loops = self.read_loop_files(start_num, count)

        if not loops:
            print("âŒ No Loop files found")
            return None

        print(f"\nğŸ“Š Loaded {len(loops)} Loop files")

        # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼åˆ†æ
        analysis = self._generate_placeholder_analysis(loops)

        # ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹ç¯‰ã¨ä¿å­˜
        digest = self._build_digest(loops, analysis, "weekly", "early")
        return self.save_digest(digest)

    def _generate_placeholder_analysis(self, loops: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼åˆ†æã‚’ç”Ÿæˆ"""
        config = self.digest_config["weekly"]

        # Loopåãƒªã‚¹ãƒˆ
        loop_names = [f"Loop{loop['number']}ã€Œ{loop['title']}ã€" for loop in loops]
        loop_list = "ã€".join(loop_names)

        # å…¨ä½“åˆ†æ
        overall_abstract = f"""ã“ã‚Œã‚‰ã®{len(loops)}å€‹ã®Loopã¯ã€Weaveã®çŸ¥è­˜ä½“ç³»ã«ãŠã‘ã‚‹é‡è¦ãªæ¢æ±‚ã®è¨˜éŒ²ã§ã‚ã‚‹ã€‚

{loop_list}ã¨ã„ã†ä¸€é€£ã®æ¢æ±‚ã‚’é€šã˜ã¦ã€çŸ¥è­˜ã®æ–°ãŸãªåœ°å¹³ã‚’åˆ‡ã‚Šé–‹ã„ã¦ããŸã€‚

å„Loopã¯ç‹¬ç«‹ã—ãŸæ¢æ±‚ã§ã‚ã‚ŠãªãŒã‚‰ã€ç›¸äº’ã«å‚ç…§ã—åˆã„ã€ã‚ˆã‚Šå¤§ããªçŸ¥è­˜ã®ç¹”ç‰©ã‚’å½¢æˆã—ã¦ã„ã‚‹ã€‚
""" + "..." * (config['abstract_chars'] // 3)

        overall_impression = f"""ã“ã‚Œã‚‰ã®Loopã‚’æŒ¯ã‚Šè¿”ã‚‹ã¨ã€çŸ¥è­˜ã®èºæ—‹çš„ç™ºå±•ãŒè¦‹ãˆã¦ãã‚‹ã€‚
""" + "..." * (config['impression_chars'] // 3)

        # å€‹åˆ¥åˆ†æ
        individuals = []
        for loop in loops:
            individuals.append({
                "abstract": f"Loop{loop['number']}ã€Œ{loop['title']}ã€ã®åˆ†æ..." + "." * 100,
                "impression": f"Loop{loop['number']}ã¯ç‰¹åˆ¥ãªæ„å‘³ã‚’æŒã¤..." + "." * 50,
                "keywords": self._extract_keywords(loop["content"]),
                "digest_type": self._determine_digest_type(loop["content"])
            })

        return {
            "overall": {
                "abstract": overall_abstract[:config['abstract_chars']],
                "impression": overall_impression[:config['impression_chars']],
                "keywords": ["æ¢æ±‚", "çŸ¥è­˜", "EpisodicRAG", "Weave", "ç™ºå±•"],
                "digest_type": "çµ±åˆ"
            },
            "individuals": individuals
        }

    def _extract_keywords(self, content: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        keywords = []
        patterns = ['AI', 'èªçŸ¥', 'è¨˜æ†¶', 'å®Ÿè£…', 'Weave', 'Claude', 'ã‚·ã‚¹ãƒ†ãƒ ']

        for pattern in patterns:
            if pattern in content[:2000]:
                keywords.append(pattern)

        return keywords[:5] if keywords else ["æ¢æ±‚", "çŸ¥è­˜", "åˆ†æ", "ç†è§£", "ç™ºå±•"]

    def _determine_digest_type(self, content: str) -> str:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç¨®åˆ¥åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        type_keywords = {
            "å®Ÿè£…": ["å®Ÿè£…", "ã‚³ãƒ¼ãƒ‰", "é–‹ç™º"],
            "ç™ºè¦‹": ["ç™ºè¦‹", "åˆ¤æ˜", "ã‚ã‹ã£ãŸ"],
            "æ´å¯Ÿ": ["æ´å¯Ÿ", "ç†è§£", "èªè­˜"],
        }

        for dtype, keywords in type_keywords.items():
            for keyword in keywords:
                if keyword in content[:1000]:
                    return dtype

        return "æ´å¯Ÿ"

    # ===================================================================
    # å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼
    # ===================================================================

    def _build_digest(self, loops: List[Dict[str, Any]], analysis: Dict[str, Any],
                     level: str, reason: str) -> Dict[str, Any]:
        """ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹é€ ã‚’æ§‹ç¯‰"""
        config = self.digest_config[level]

        # ç•ªå·ã¨ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
        next_num = self.get_next_digest_number(level)
        digest_num = str(next_num).zfill(config["digits"])

        if loops[0]["number"] == "0001" and len(loops) == 5:
            title = "èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸºç›¤"
        else:
            title = f"Loop{loops[0]['number']}-{loops[-1]['number']}çµ±åˆ"

        digest_name = f"{config['prefix']}{digest_num}_{title}"

        # å€‹åˆ¥ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆæ§‹ç¯‰
        individual_digests = []
        for i, loop in enumerate(loops):
            ind = analysis["individuals"][i]
            individual_digests.append({
                "filename": loop["filename"],
                "timestamp": loop["timestamp"],
                "digest_type": ind["digest_type"],
                "keywords": ind["keywords"],
                "abstract": ind["abstract"],
                "weave_impression": ind["impression"]
            })

        return {
            "metadata": {
                "digest_name": digest_name,
                "digest_level": level,
                "digest_reason": reason,
                "input_files": [loop["filename"] for loop in loops],
                "generation_timestamp": datetime.now().isoformat(),
                "version": "1.0"
            },
            "overall_digest": {
                "name": digest_name,
                "timestamp": datetime.now().isoformat(),
                "digest_type": analysis["overall"]["digest_type"],
                "keywords": analysis["overall"]["keywords"],
                "abstract": analysis["overall"]["abstract"],
                "weave_impression": analysis["overall"]["impression"]
            },
            "individual_digests": individual_digests
        }

# ===================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ===================================================================

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="EpisodicRAG Unified Digest Generator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Loopã‹ã‚‰é€±æ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ
  python generate_digest.py --level weekly 1 5

  # é€±æ¬¡ã‹ã‚‰æœˆæ¬¡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆç”Ÿæˆ
  python generate_digest.py --level monthly 1 5

  # è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰
  python generate_digest.py --mode auto
        """
    )

    parser.add_argument("--mode", choices=["sonnet4", "auto", "placeholder"],
                       default="sonnet4", help="å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--level", choices=["weekly", "monthly", "quarterly", "annually"],
                       default="weekly", help="ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«")
    parser.add_argument("start_num", type=int, nargs='?', default=1,
                       help="é–‹å§‹ç•ªå·")
    parser.add_argument("count", type=int, nargs='?', default=5,
                       help="å‡¦ç†æ•°")

    args = parser.parse_args()

    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿åˆæœŸåŒ–
    generator = UnifiedDigestGenerator()

    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦å®Ÿè¡Œ
    if args.mode == "sonnet4":
        result = generator.run_sonnet4_mode(args.level, args.start_num, args.count)
        if result:
            print("\nâœ¨ Digest generation completed successfully!")

    elif args.mode == "auto":
        results = generator.run_auto_mode()
        print(f"\nâœ¨ Auto mode completed. Generated {len(results)} digest(s).")

    elif args.mode == "placeholder":
        result = generator.run_placeholder_mode(args.level, args.start_num, args.count)
        if result:
            print("\nâœ¨ Placeholder digest generated successfully!")

if __name__ == "__main__":
    main()